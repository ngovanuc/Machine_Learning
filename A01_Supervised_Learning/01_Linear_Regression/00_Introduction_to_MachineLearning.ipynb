{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Ngo Van Uc\n",
    "Date: 30/10/2024\n",
    "Contact: ngovanuc.1508@gmail.com\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "- Một bài toán Machine Leanring thông thường có 2 nhiệm vụ:\n",
    "    + Bài toán dự đoán (Regression)\n",
    "    + Bài toán phân loại (Classification)\n",
    "\n",
    "- Các thuật toán Regression\n",
    "    + Linear Regression (Hồi quy tuyến tính): Mô hình hồi quy đơn giản nhất dựa trên đường thẳng.\n",
    "    + Polynomial Regression (Hồi quy đa thức): Dễ overfitting nếu chọn bậc đa thức quá cao.\n",
    "    + Ridge Regression (Hồi quy Ridge) và Ridge Regression (Hồi quy Ridge): \n",
    "    + Elastic Net Regression: Giúp lựa chọn đặc trưng vừa giảm bớt overfitting với dữ liệu có nhiều đặc trưng không quan trọng.\n",
    "    + Support Vector Regression (SVR): SVR là phiên bản hồi quy của SVM\n",
    "    + Decision Tree Regression: Sử dụng cây quyết định để phân chia dữ liệu thành các tập con nhỏ, dễ bị overfitting, rất mạnh với dữ liệu không tuyến tính.\n",
    "    + Random Forest Regression: Sử dụng tổ hợp nhiều cây quyết định và trung bình dự đoán từ các cây này để giảm thiểu overfitting.\n",
    "    + Gradient Boosting Regression: Tương tự như Random Forest nhưng áp dụng thuật toán boosting để cải thiện hiệu suất (biến thể: XGBoost, LightGBM, và CatBoost )\n",
    "    + K-Nearest Neighbors Regression (KNN): \n",
    "    + Neural Networks Regression: Với dữ liệu lớn và phức tạp, các mạng nơ-ron như Multi-Layer Perceptron (MLP) hoặc các mạng sâu khác (Deep Learning) thường được dùng để tạo mô hình hồi quy mạnh mẽ.\n",
    "    + Bayesian Regression: Dùng xác suất và thống kê để dự đoán với phân phối Bayesian\n",
    "    \n",
    "    => Đối với mỗi thuật toán sẽ có ưu và nhược điểm riêng, tùy từng nhiệm vụ và chọn ra thuật toán phù hợp hoặc thử nghiệm\n",
    "\n",
    "- Các thuật toán Classification:\n",
    "    + Logistic Regression: \n",
    "    + K-Nearest Neighbors (KNN)\n",
    "    + Support Vector Machine (SVM)\n",
    "    + Naive Bayes\n",
    "    + Decision Tree (Cây Quyết Định)\n",
    "    + Random Forest\n",
    "    + Gradient Boosting và các biến thể (XGBoost, LightGBM, CatBoost)\n",
    "    + Neural Networks (Mạng Nơ-ron)\n",
    "    + Bagging (Bootstrap Aggregating)\n",
    "    + AdaBoost (Adaptive Boosting)\n",
    "    + Deep Learning Models for Classification (Tìm hiểu dần)\n",
    "\n",
    "    => Đối với mỗi thuật toán sẽ có ưu và nhược điểm riêng, tùy từng nhiệm vụ và chọn ra thuật toán phù hợp hoặc thử nghiệm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Các bước để huấn luyện một mô hình\n",
    "\n",
    "- Hầu hết việc training một mô hinh dường như tuân theo những bước sau đây:\n",
    "    + Thu thập hoặc chọn dữ liệu\n",
    "    + Khai phá (khám phá - exploring) dữ liệu\n",
    "    + Tiền xử lí dữ liệu\n",
    "    + Lựa chọn model phù hợp\n",
    "    + Xây dựng model\n",
    "    + Huấn luyện model\n",
    "    + Đánh giá hiệu suất model trên dữ liệu kiểm thử\n",
    "    + Tinh chỉnh dữ liệu (nếu cần và tiếp tục quay lại huấn luyện)\n",
    "    + Tinh chỉnh siêu tham số mô hình (nếu cần và tiếp tục quay lại huấn luyện)\n",
    "    + Thực hiện predict trên một mẫu mới\n",
    "    ...\n",
    "\n",
    "- Thu thập dữ liệu\n",
    "    + Tự thu thập hoặc lấy dữ liệu sẵn công khai\n",
    "\n",
    "- Khai phá dữ liệu:\n",
    "\n",
    "    ***Trong nhiều trường hợp, việc hiểu dữ liệu là cần thiết***\n",
    "    + Đọc mô tả dữ liệu\n",
    "    + Xem thống kê số liệu\n",
    "    + Xem các thông tin chi tiết liên quan đến dữ liệu\n",
    "    + Trực quan hóa dữ liệu\n",
    "    + Vẽ viểu đồ...\n",
    "    + Kiểm tra các giá trị ngoại lai (outlier)\n",
    "    + Kiểm tra các giá trị thiếu (Nan)\n",
    "    + Tìm hiểu mối tương quan của các đặc trưng trong dữ liệu   \n",
    "\n",
    "- Tiền xử lí dữ liệu\n",
    "    + Xử lí dữ liệu thiếu (missing/Nan): điền giá trị 0, thay bằng giá trị trung bình, trung vị, loại bỏ...\n",
    "    + Loại bỏ đi các đặc trưng không cần thiết (dựa vào sự tương quan)\n",
    "    + Xử lí dữ liệu bị nhiễu: loại bỏ, hoặc thay thế giá trị hợp lí (trung bình, trung vị)\n",
    "    + Biến đổi dữ liệu: chuyển về khoảng [0,1] hoặc [-1,1]\n",
    "    + Mã hóa đặc trưng: Chuyển dữ liệu dạng chữ về con số \n",
    "    + Giảm chiều dữ liệu: thông thường sử dụng PCA, feature selection\n",
    "    + Chia tách dữ liệu thông thường training - validation - testing là 70 - 10 -20\n",
    "    + Đối với dữ liệu mất cân bằng: Kỹ thuật Resampling và Data Augmentation (Làm giàu data), Tạo đặc trưng mới\n",
    "    ...\n",
    "\n",
    "- Lựa chọn mô hình phù hợp:\n",
    "\n",
    "    ***cần cân nhắc nhiều yếu tố liên quan đến đặc điểm dữ liệu, mục tiêu bài toán và các yêu cầu cụ thể của ứng dụng.***\n",
    "    + Hiểu về Dữ liệu và Bài toán:\n",
    "        + Loại bài toán: Xác định loại bài toán là Classification, Regression, Clustering, hay Recommendation. Việc này sẽ giúp thu hẹp lựa chọn mô hình.\n",
    "        + Đặc điểm dữ liệu: Dữ liệu có bao nhiêu mẫu (samples), kích thước dữ liệu, các đặc trưng có dạng phân loại hay liên tục, có bị nhiễu không và có cân bằng hay không.\n",
    "        + Yêu cầu của ứng dụng: Độ chính xác, độ phức tạp, thời gian huấn luyện và tính dễ giải thích của mô hình đều cần cân nhắc kỹ trước khi lựa chọn mô hình.\n",
    "\n",
    "    + Chọn Mô hình Dựa trên Đặc điểm Dữ liệu và Mục tiêu:\n",
    "        + Dữ liệu nhỏ, tuyến tính: Các mô hình đơn giản như Linear Regression (cho regression), Logistic Regression (cho classification) hoặc Naive Bayes sẽ hiệu quả và dễ triển khai.\n",
    "        + Dữ liệu không tuyến tính hoặc nhiều nhiễu: Các mô hình Decision Tree, Random Forest, SVM với kernel, hoặc Neural Networks sẽ phù hợp.\n",
    "        + Dữ liệu lớn và phức tạp: Các mô hình mạnh như Gradient Boosting (XGBoost, LightGBM) cho regression và classification, hoặc Deep Learning (CNN, RNN) cho các bài toán với dữ liệu hình ảnh, chuỗi thời gian, hoặc văn bản.\n",
    "    \n",
    "- Huấn luyện model:\n",
    "    + Xây dựng model\n",
    "    + Huấn luyện model\n",
    "    + Theo dõi kết quả (nếu có)\n",
    "\n",
    "- Đánh giá hiệu suất model trên dữ liệu kiểm thử:\n",
    "\n",
    "    ***Với mỗi bài toán, việc lựa chọn phương pháp đánh giá hiệu suất model là khác nhau***\n",
    "    ***Phương Pháp Chọn Chỉ Số Đánh Giá:***\n",
    "    + Dựa trên loại bài toán:\n",
    "        + Classification (phân loại): Các chỉ số như Accuracy, Precision, Recall, F1-score, và ROC-AUC thường được sử dụng.\n",
    "        + Regression (hồi quy): Các chỉ số như Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), và R-squared (R²) sẽ phù hợp hơn.\n",
    "        + Clustering (phân cụm): Sử dụng Silhouette Score, Davies-Bouldin Index, và Inertia để đánh giá độ phân cụm.\n",
    "    \n",
    "    + Dựa trên yêu cầu bài toán:\n",
    "        + Nếu cần độ chính xác cao và tránh lỗi dương tính giả (false positives) như trong chẩn đoán y khoa, Precision và F1-score có thể quan trọng hơn.\n",
    "        + Đối với bài toán yêu cầu giảm thiểu lỗi dự đoán, chẳng hạn như dự báo giá trị, cần tập trung vào các chỉ số lỗi như MSE hoặc MAE.\n",
    "    \n",
    "    + Cân nhắc giữa các chỉ số để đạt cân bằng:\n",
    "        + Trong một số trường hợp, một chỉ số riêng lẻ không đủ để đánh giá toàn diện mô hình, như với các bài toán mất cân bằng (imbalanced datasets). Trong trường hợp này, việc sử dụng cả Precision, Recall và F1-score sẽ hữu ích hơn là chỉ dựa vào Accuracy.\n",
    "\n",
    "- Tinh chỉnh dữ liệu (nếu cần và tiếp tục quay lại huấn luyện)\n",
    "- Tinh chỉnh siêu tham số mô hình (nếu cần và tiếp tục quay lại huấn luyện)\n",
    "    + Việc phải xử lí lại dữ liệu mục đích thử nghiệm để tìm ra những đặc trưng tốt nhất\n",
    "    + Cần phải tinh chỉnh siêu tham số mô hình để tìm ra được kết quả tốt nhất\n",
    "    + Sau khi thực hiện những điều trên thì quay lại huấn luyện xem kết quả cải thiện hơn không\n",
    "\n",
    "- Thực hiện predict trên một mẫu mới:\n",
    "    + Sau khi training model thì thực hiện predict trên dữ liệu test hoặc dữ liệu mới bất kỳ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
