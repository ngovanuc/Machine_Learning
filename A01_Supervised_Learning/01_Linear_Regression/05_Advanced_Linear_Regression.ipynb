{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Author: Ngo Van Uc\n",
    "Date: 11/11/2024\n",
    "Contact: ngovanuc.1508@gmal.com\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Tìm hiểu:***\n",
    "- Fitting là gì?\n",
    "- Overfitting là gì?\n",
    "- Underfitting là gì?\n",
    "\n",
    "***Các kĩ thuật điều khiển Overfitting:***\n",
    "- Regularization trong Linear Regression (Ridge và Lasso)\n",
    "    + Ridge Regression: phạt vào hàm mất mát để giảm bớt độ phức tạp của mô hình. có tác dụng làm giảm phương sai (variance) nhưng giữ lại độ chệch (bias), hữu ích khi dữ liệu có nhiều nhiễu (noise) hoặc đa cộng tuyến (multicollinearity).\n",
    "    + Lasso Regression: phạt để làm giảm các hệ số của một số đặc trưng về đúng 0. giúp chọn lọc đặc trưng (feature selection) vừa tránh overfitting. hữu ích khi muốn làm đơn giản mô hình bằng cách loại bỏ các biến không quan trọng.\n",
    "- Multicollinearity (Đa cộng tuyến)\n",
    "    + Khi các biến độc lập (independent variables) có tương quan mạnh với nhau, phương pháp hồi quy tuyến tính có thể bị ảnh hưởng nặng nề do các biến không đóng góp thêm thông tin mới mà chỉ tạo thêm nhiễu.\n",
    "    + Phát hiện: Sử dụng hệ số tương quan hoặc chỉ số VIF (Variance Inflation Factor).\n",
    "    + Giải quyết: Sử dụng Ridge Regression, Lasso Regression, hoặc phương pháp chính tắc (Principal Component Analysis - PCA) để giảm bớt tương quan giữa các biến.\n",
    "    + Biến độc lập (kí hiệu là X, biến phụ thuộc kí hiệu là Y theo một cách thông thường nào đó)\n",
    "- Polynomial Regression và Nonlinear Transformations (Hồi quy đa thức và biến đổi phi tuyến tính)\n",
    "    + Linear Regression chỉ hữu ích khi dữ liệu tuyến tính, nhưng nếu quan hệ giữa biến độc lập và biến phụ thuộc là phi tuyến, ta có thể chuyển đổi dữ liệu bằng cách thêm các đặc trưng đa thức (polynomial features) hoặc sử dụng các phép biến đổi hàm (exponential, log) để mô hình hóa mối quan hệ phức tạp hơn.\n",
    "    + Lưu ý: Cần cẩn thận khi thêm các đặc trưng vì nó có thể dẫn đến overfitting nếu không có kỹ thuật điều chỉnh thích hợp.\n",
    "- Outlier và Influential Points\n",
    "    + Outliers có thể ảnh hưởng lớn đến mô hình hồi quy, đặc biệt nếu là influential points (các điểm có ảnh hưởng mạnh lên hệ số hồi quy).\n",
    "    + Phát hiện: Dùng Cook's Distance hoặc leverage points để xác định các điểm có ảnh hưởng mạnh.\n",
    "    + Giải pháp: Nếu phát hiện outliers có thể gây nhiễu, bạn có thể loại bỏ chúng hoặc sử dụng các mô hình hồi quy robust (Robust Regression) để giảm ảnh hưởng của các outlier.\n",
    "- Assumption Violations (Vi phạm Giả định) và Kiểm tra Giả định\n",
    "    + Hồi quy tuyến tính dựa vào nhiều giả định (normality, linearity, independence, homoscedasticity) để có được các ước lượng chính xác.\n",
    "    + Kiểm tra giả định:\n",
    "        + Sử dụng đồ thị phần dư (residual plots) để kiểm tra tính tuyến tính và tính đồng nhất của phương sai.\n",
    "        + Dùng biểu đồ Q-Q (Quantile-Quantile Plot) để kiểm tra normality.\n",
    "        + Sử dụng kiểm định Durbin-Watson để phát hiện tự tương quan trong dữ liệu chuỗi thời gian.\n",
    "- Feature Engineering và Interaction Terms (Kỹ thuật tính năng và thuật ngữ tương tác)\n",
    "    + Tạo các đặc trưng tương tác (interaction terms) giữa các biến để mô hình có thể biểu diễn mối quan hệ phức tạp giữa các biến.\n",
    "    + Ngoài ra, có thể thực hiện các phép biến đổi khác nhau trên biến (ví dụ log, root, square) để có được mối quan hệ tuyến tính hơn với biến mục tiêu.\n",
    "- Kỹ thuật Feature Selection nâng cao\n",
    "    + Recursive Feature Elimination (RFE): Loại bỏ tuần tự các đặc trưng ít quan trọng nhất cho đến khi đạt được bộ đặc trưng tối ưu.\n",
    "    + Regularized Models (như Lasso) để chọn lọc đặc trưng tự động.\n",
    "    + Statistical Tests: Kiểm định t-test cho các hệ số để xác định biến nào là quan trọng.\n",
    "- Bayesian Linear Regression\n",
    "    + Sử dụng phương pháp Bayesian thay vì tối ưu hóa để tìm phân phối xác suất của các hệ số, giúp cung cấp không chỉ một giá trị duy nhất mà còn là độ không chắc chắn (uncertainty) của mỗi hệ số.\n",
    "    + Điều này có lợi khi làm việc với các dữ liệu không chắc chắn hoặc khi bạn cần mô hình hồi quy cung cấp độ tự tin về dự đoán.\n",
    "- Generalized Linear Models (GLMs) - Mô hình tuyến tính tổng quát (GLM)\n",
    "    + Nếu biến mục tiêu không phải là biến liên tục hay phân phối chuẩn, các Generalized Linear Models như logistic regression (cho dữ liệu nhị phân), Poisson regression (cho dữ liệu đếm) sẽ giúp mô hình hóa các dữ liệu phi tuyến tính hoặc phi chuẩn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Ridge và Lasso Regression (Sử dụng dữ liệu nhà ở từ Scikit-Learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://phamdinhkhanh.github.io/deepai-book/ch_ml/RidgedRegression.html\n",
    "- Ridge và Lasso rất phù hợp với dữ liệu nhiều đặc trưng để kiểm soát overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Load data\n",
    "data = load_boston()\n",
    "x, y = data.data, data.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ridge regression\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(x_train, y_train)\n",
    "ridge_pred = ridge.predict(x_test)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(x_train, y_train)\n",
    "lasso_pred = lasso.predict(x_test)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_pred)\n",
    "\n",
    "print(f\"Ridge MSE: {ridge_mse}\")\n",
    "print(f\"Lasso MSE: {lasso_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Multicollinearity Detection (Sử dụng hệ số VIF với dữ liệu kinh tế giả lập)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://en.wikipedia.org/wiki/Multicollinearity\n",
    "- Phát hiện đa cộng tuyến trong các biến độc lập."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Giả lập dữ liệu với đa cộng tuyến\n",
    "np.random.seed(42)\n",
    "X1 = np.random.rand(100)\n",
    "X2 = 2 * X1 + np.random.normal(0, 0.1, 100)  # X2 có tương quan cao với X1\n",
    "X3 = np.random.rand(100)\n",
    "y = 3 * X1 + 2 * X3 + np.random.normal(0, 0.1, 100)\n",
    "\n",
    "df = pd.DataFrame({'X1': X1, 'X2': X2, 'X3': X3, 'y': y})\n",
    "\n",
    "# Tính VIF cho mỗi biến\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = df.columns[:-1]\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(df.iloc[:, :-1].values, i) for i in range(df.iloc[:, :-1].shape[1])]\n",
    "\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Polynomial Regression (Sử dụng dữ liệu mức độ ô nhiễm không khí và thời gian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mô hình hóa mối quan hệ phi tuyến giữa các biến.\n",
    "- https://www.sciencedirect.com/topics/computer-science/polynomial-regression#:~:text=Polynomial%20regression%20is%20a%20form,variables%20compared%20to%20linear%20regression.\n",
    "- https://en.wikipedia.org/wiki/Polynomial_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Giả lập dữ liệu\n",
    "np.random.seed(0)\n",
    "X = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "y = 4 * (X ** 2) + np.random.normal(0, 10, X.shape[0]).reshape(-1, 1)\n",
    "\n",
    "# Polynomial Regression\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_poly, y)\n",
    "y_poly_pred = model.predict(X_poly)\n",
    "\n",
    "print(\"Polynomial Regression Model Coefficients:\", model.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Weighted Least Squares (WLS) Regression cho Heteroscedasticity (Sử dụng dữ liệu giả lập với phương sai không đồng nhất)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Dữ liệu giả lập\n",
    "np.random.seed(42)\n",
    "X = np.random.normal(size=100)\n",
    "y = 2 * X + 1 + np.random.normal(scale=(0.5 + X), size=100)  # Phương sai thay đổi theo X\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "wls_model = sm.WLS(y, X, weights=1 / (0.5 + X.flatten())).fit()\n",
    "print(wls_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Outlier Detection using Cook's Distance (Sử dụng dữ liệu sức khỏe từ Scikit-Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load dữ liệu\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Tạo mô hình hồi quy và tính Cook's Distance\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X).fit()\n",
    "influence = model.get_influence()\n",
    "cooks = influence.cooks_distance\n",
    "\n",
    "# Xác định các điểm outlier\n",
    "outliers = cooks[0] > 4 / X.shape[0]\n",
    "print(\"Indices of outliers:\", np.where(outliers))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Assumption Checks - Normality, Linearity, Independence (Sử dụng dữ liệu lượng mưa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import probplot\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Giả lập dữ liệu tuyến tính\n",
    "np.random.seed(0)\n",
    "X = np.random.normal(0, 1, 100).reshape(-1, 1)\n",
    "y = 3 * X.flatten() + np.random.normal(0, 1, 100)\n",
    "\n",
    "# Fit model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "residuals = y - y_pred\n",
    "\n",
    "# Kiểm tra linearity và residuals\n",
    "sns.scatterplot(x=y_pred, y=residuals)\n",
    "plt.xlabel(\"Fitted values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plot for normality\n",
    "probplot(residuals, plot=plt)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Bayesian Linear Regression (Sử dụng dữ liệu tài chính với phương pháp Bayesian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Model Coefficients: [4.85449211]\n",
      "Model Intercept: 0.007194098956850303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "# Dữ liệu giả lập\n",
    "np.random.seed(42)\n",
    "X = np.random.normal(0, 1, 100).reshape(-1, 1)\n",
    "y = 5 * X.flatten() + np.random.normal(0, 1, 100)\n",
    "\n",
    "# Bayesian Linear Regression\n",
    "bayesian_model = BayesianRidge()\n",
    "bayesian_model.fit(X, y)\n",
    "\n",
    "print(\"Bayesian Model Coefficients:\", bayesian_model.coef_)\n",
    "print(\"Model Intercept:\", bayesian_model.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Generalized Linear Models (GLMs) (Dữ liệu y học với hồi quy logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dữ liệu\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Fit GLM logistic model\n",
    "glm_logistic = LogisticRegression(max_iter=10000)\n",
    "glm_logistic.fit(X, y)\n",
    "\n",
    "y_pred = glm_logistic.predict(X)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
